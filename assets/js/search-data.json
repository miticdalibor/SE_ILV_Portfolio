{
  
    
        "post0": {
            "title": "01 Requirements",
            "content": "Funktionale Requirements . Unter der Bedingung, dass der User alle Features des importierten Datensatzes über das UI kategorisiert hat und die Funktion &quot;Free Lunch&quot; gestartet hat, muss die Pipeline des Systems in der Lage sein, den Datensatz eigenständiig für das Modelltraining vorzubereiten. . | Wenn der importierte Datensatz der Pipeline übergeben wurde, soll die Pipeline fähig sein, Spalten mit nur fehlenden Daten abzufragen und aus dem Datensatz zu löschen. . | Wenn der importierte Datensatz der Pipeline übergeben wurde, soll die Pipeline fähig sein, fehlende numerische Daten in einer Zeitserie durch einen Extremwert zu ersetzen. . | Wenn der importierte Datensatz der Pipeline übergeben wurde, soll die Pipeline fähig sein, fehlende kategorische Daten aus dem Datensatz zu entfernen. . | Wenn der importierte Datensatz der Pipeline übergeben wurde, soll die Pipeline fähig sein, entsprechend die numerischen Features zu skalieren zwischen 0 und 1 (MinMaxScaler). . | Wenn der vom User importierte Datensatz durch das Starten der &quot;Frunch Infinity 2.0&quot; Funktion vorverarbeitet wurde, sollen unterschiedliche konventionelle Modelle trainiert werden. . | . User Interface . Wenn der User die App startet, soll das System fähig sein, individuelle Datensätze zu importieren. . | Wenn der User einen beliebigen Datensatz über das UI importiert, muss die App &quot;Frunch Infinity 2.0&quot; die Möglichkeit bieten, die Feature-Bezeichnungen dem User anzuzeigen und der User soll entsprechend jedes Feature als numerisch oder kategorisch sowie die Zielvariable auswählen. . | Unter der Bedingung, dass der User alle Features des importierten Datensatzes über das UI kategorisiert hat und die Zielvariable kategorisch ist, soll die Applikation die Anzahl der unterschiedlichen Klassen in der Zielvariable sowie die Klassenbalance anzeigen. . | Wenn der User die Funktion &quot;Frunch Infinity 2.0&quot; gestartet hat, soll die Applikation fähig sein, dem User eine Auswahl von Metriken zum Vergleich der trainierten Modelle anbieten. . | Wenn das Training mit unterschiedlichen Modellen abgeschlossen ist, sollen die Ergebnisse mit den ausgewählten Metriken in einer Tabelle dem User über das UI angezeigt werden. . | Wenn der User die Applikation startet, soll das System die Möglichkeit anbieten, den Log einzusehen und zu exportieren von der APP. . | . UML Diagramm der zentralen Requirements . . Änderungen von Requirements . Da die gesamte Implementierung nach dem Agile-Prinzip über das Kanban-Board von Gitlab erfolgt (siehe Beispiel in der nachfolgenden Abbildung), können entsprechende Änderungen von Requirements über dieses Board eingefangen und koordiniert werden. . . Dabei kann das neue Requirement oder geänderte Requirement als neues Issue im Produkt-Backlog aufgenommen werden. Um dieses Issue von den anderen zu unterscheiden, soll in der Beschreibung des Issues eine Change-Request ID hinzugefügt werden (z.B. CR-001). Im nächsten Sprint soll entsprechend der Impact bewertet werden. Ist der Impact zu groß, muss entsprechend mit dem Kunden Rücksprache gehalten werden. Sobald der Implementierungsplan aus dem geänderten Requirement aufeesetzt ist, werden daraus ableitend entsprechend neue Issues für das Projektteam angelegt. Jedes Issue, welches aus dem CR-001 erstellt wurde, wird entsprechend mit einem Flag kategorisiert, um den Abschluss des CR zu sehen. Abschließend wird die Dokumentation der Requirements angepasst. . Mögliche Veränderungen von Requirements wären beispielsweise: . Neue Edge-Cases in den zu importierenden Datensätzen, die die Pipeline verarbeiten muss. . | Model-Explanation: Der User will das Training der Modelle überwachen und dies muss entsprechend über das UI ausgegeben oder in einem Log-File gespeichert werden. . | Das beste Modell soll gespeichert werden, damit der User dies auf einem ähnlichen Datensatz anwendet. . | .",
            "url": "https://miticdalibor.github.io/SE_ILV_Portfolio/markdown/2022/07/03/requirements.html",
            "relUrl": "/markdown/2022/07/03/requirements.html",
            "date": " • Jul 3, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "02 Architektur",
            "content": "Systemarchitektur . Die Systemarchitektur für Frunch Infinity 2.0 stellt eine Client-Server-Architektur dar. Dabei soll der User entsprechend über den Client die Applikation im Browser öffnen und dort dessen Datensatz importieren und die Ergebnisse entsprechend lesen können. Das Trainieren der Modelle läuft im Backend auf der Server-Seite. Deshalb ist es notwendig hier den Server entsprechend für hohe Rechenleistungen auszulegen, damit auch große Datensätze verarbeitet werden können. Das Backend wird in Python implementiert und die Daten werden entsprechend in einem Data-Warehouse abgelegt. Das Frontend wird in React umgesetzt, um flexibel in der Implementierung der Web-App zu sein und auf spezifische User-Anforderungen reagieren zu können. Das Frontend benötigt die Daten vom Backend im .json Format, damit es diese in der Web-App verarbeiten kann. Hierzu wird FastAPI implementiert, da es Flexibilität im Datenaustausch bietet, sehr performant ist und automatisch eine Dokumentation generiert. Eine mobile App ist für Frunch Infinity 2.0 nicht erforderlich, da die Datensätze vom User nicht auf einem iPhone liegen. . Schnittstellen . - Da Frunch Infinity 2.0 eine Enterprise Solution ist, soll das System im firmeneigenen Intranet aufgesetzt werden, damit die Kunden die Daten nicht nach außen vergeben müssen. Deshalb muss auch die Verwaltung und das Management der Server-Hardware von der IT-Abteilung des Kunden erfolgen. Somit sind folgende Schnittstellen nicht anwendbar: . - Schnittstellen zu Internet-Webseiten und Web-Scraper . - Schnittstellen zu Cloud-Services (Datawarehouse liegt beim Kunden) . - Schnittstelle zu Softwareentwickler, da kein Transfer-Learning mit geteilten Daten angewendet wird . Für das ablegen der Docker-Registry auf Dockerhub ist entsprechend die Schnittstelle vom Intranet nach außen erforderlich. Außerdem müssen entsprechende Downloads von Packages gewährleistet werden. Hierbei sollen die Packages nur mit Hashes installiert werden, um keine &quot;gefälschten&quot; Open-Source Packages zu installieren. . Systemarchitektur Diagramm . Die nachfolgende Grafik zeigt eine Übersicht der Architektur. Die gelb markierten Blöcke befinden sich im Frontend und die blau markierten Blöcke im Backend. . . Der User soll dabei die Daten aus dem lokalen Speicher in einem .csv Format über die Web-App (Client) hochladen. Über die Web-App soll der User dann die Feature-Bezeichnungen definieren und entsprechend als numerisch oder kategorisch markieren, sowie die Zielvariable auswählen. Sobald die Funktion gestartet wird, werden die Daten entsprechend über eine Pipeline preprocessed und im Datawarehouse abgelegt (Server). Von dort aus werden die preprocessed Daten geladen, die Modelle trainiert und die Ergebnisse entsprechend gespeichert und ausgegeben. . Datawarehouse . Als Datawarehouse für Frunch Infinity ist ein Enterprise Data Warehouse erforderlich, damit die Daten zentralisiert gelagert werden. Für die Architektur der untersten Ebene im Datawarehouse können keine besonderen Anforderungen außer der Konsistenz der Daten abgeleitet werden. Die Zeit für das Schreiben und Lesen der Daten im Datawarehouse ist im Vergleich zur Trainingszeit der Modelle marginal und somit besteht keine Echtzeitanforderung. Es ist aber wichtig, dass die Daten konsistent sind, damit die Integrität der Daten über den gesamten Lebenszyklus gegeben ist. Deshalb wird als Architektur ein relationales DBS (MySQL) gewählt. Der Zugriff auf das Datawarehouse kann über SQLAlchemy (ORM) erfolgen und für die Verwaltung der importierten Datensätze wird DVC (Data Version Control) verwendet (bevor sie in das Datawarehouse abgelegt werden). . CI/CD Pipeline . Die CI/CD Pipeline für Frunch Infinity 2.0 enthält folgende Stages: . Test: Ausführen der unit-tests (run pytest) . | Pages: Ausführen von pdoc, um Dokumentation der Klassen zu erstellen. . | Build: Erstellen eines Docker-Images und speicher in einer Registry auf Gitlab. Die Build-Stage soll nur beim Tag (neuer Software Release) ausgeführt werden. . | Deploy: Die Applikation soll deployed werden, wenn ein Release erfolgreich gebuilded wurde. . | . Beispiel: Entwicklung des Features &quot;import Data&quot;, mit dem der User eigene .csv-Files über die Web-App hochladen kann. . 1) pytest wird um eine Klasse &quot;test_file_format&quot; erweitert. Dabei wird ein assert error eingefügt, der die File-Extension &quot;*.csv&quot; überprüft und entsprechend einen Fehler &quot;Please import only files in .csv file format&quot; ausgibt. . 2) Implementierung in Web-App durchführen und importierte Daten als .json an Backend übergeben. . 3) Commit durchführen . 4) Pytest in CI wird durchgeführt. Wenn Test bestanden hat, dann weiter mit Schritt 5. . 5) Doc-String von Klassen &quot;test_file_format&quot; und &quot;import_data&quot; wird mit pdoc erstellt und als html abgelegt. . 6) Feature releasen in Gitlab. . 7) Build wird durchgeführt (siehe oben) . 8) App wird deployed. . Data-Science Architektur . Nachfolgendes Diagramm zeigt eine eigens entwickelte Data-Science Architektur für Frunch-Infinity 2.0 auf Basis des CRISP-DM Ansatzes, welches in der Produktion angewendet wird. Für den Development Prozess kann der klassische CRISP-DM Ansatz angewendet werden und deshalb wird dieser hier nicht näher betrachtet. . . Da Frunch-Infinity eine Auto-ML Lösung darstellt, liegt der Business Understanding (Domänenwissen) auf der User-Seite. Der User soll durch die Anwendung von Frunch-Infinity 2.0 einen Einblick in die Qualität der verwendeten Daten kriegen und somit das Verständnis der Daten verbessern. Damit das System flexibel ist muss die Data-Preparation und das Modelling ein Netzwerk darstellen, wodurch alle möglichen Szenarien durchberechnet werden. Der Evaluation-Teil vergleicht die Ergebnisse der Modelle und schaltet mit jeder Iteration durch alle Pipelines. Wenn alle Iterationen durchgelaufen sind, vergleicht der Evaluation-Teil die besten Ergebnisse der Iterationen mit einander und gibt das Modell mit dem besten Ergebnis aus. Am meisten Entwicklungsaufwand für Frunch-Infinity 2.0 wird der Teil Data Preprocessing sein, da die Pipeline unterschiedlichste Datensätze und Edge-Cases verarbeiten muss. Die Architektur soll die Möglichkeit bieten, dem User die Data Preparation sowie das beste Modell ausgeben, wodurch das Data Understanding durch die Anwendung von Frunch Infinity 2.0 erreicht wird. .",
            "url": "https://miticdalibor.github.io/SE_ILV_Portfolio/markdown/2022/07/02/Architektur.html",
            "relUrl": "/markdown/2022/07/02/Architektur.html",
            "date": " • Jul 2, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "03 Design & Tools",
            "content": "Design Pattern . Für Frunch Infinity 2.0 werden das Factory Design Pattern (Creational patterns) sowie Decorators (Structural patterns) eingesetzt. Beispiel: Damit die Preprocessing-Pipeline unterschiedliche Datensätze verarbeiten kann, muss diese durch unterschiedliche Klassen implementiert werden, welche entsprechende Basis-Methoden enthalten und durch Edge-Cases erweitert werden können. Dabei werden entsprechend einige Klassen mit einem Decorator ausgestattet. Durch entsprechendes Refactoring soll der Code entsprechend strukturiert und sauber gehalten werden. Mit den gewählten Design Patterns und Refactoring soll das System skalierbar sein. . Tools . Neben den Tools bzw. Frameworks, welche zur Entwicklung des Systems angewendet werden (siehe Abbildung &quot;Systemarchitektur und Tools&quot;) werden folgende Tools unterstützend für die Umsetzung angewendet: . Poetry: Wird zum Package Management und Dependencies angewendet. . - Vorteil: Poetry übernimmt die automatische Überprüfung der Dependencies und spart dem Entwickler viel Zeit. . | Hydra: Management von Pfaden sowie die zentrale Konfigurationen. . - Vorteil: Dadurch ist das System flexibler und Änderungen von Anforderungen können einfacher umgesetzt werden. . | Cookiecutter: Vorgabe der Repository-Struktur und einiger Basic Tools. . - Vorteil: Gute Basis für die Anfangsphase der Entwicklung und gibt einen Weg bzw. eine Struktur vor. Enthält einige Tools (z.B. black, flake8, isort, nbstripout etc.), welche den Code durch Überprüfungen während des Commits clean halten. . | Docker: Erstellt eine virtuelle Umgebung für eine einfachere Entwicklung und Build. . | Logging: Entsprechende Schritte im System werden geloggt, um ein leichteres Debugging zu gewährleisten. . - Beispiele: Ausgabe vom Modelltraining, Schreiben/Lese in die DB etc. . | Unit tests: Test Driven Development (TDD) . - Beispiel: Die Klassen der Pipeline müssen auf assert error getestet. . | Pdoc: Automatische Dokumentation von Klassen (Docstrings nur in English). . | .",
            "url": "https://miticdalibor.github.io/SE_ILV_Portfolio/markdown/2022/07/01/Design.html",
            "relUrl": "/markdown/2022/07/01/Design.html",
            "date": " • Jul 1, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Name: Ing. Dalibor Mitic, BSc. . Kurs: Softwareentiwcklung 2 . Jahrgang: DSIA 2021/22 . Studiengang: Data Science &amp; Intelligent Analytics . Institut: Fachhochschule Kufstein . This website is powered by fastpages. .",
          "url": "https://miticdalibor.github.io/SE_ILV_Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://miticdalibor.github.io/SE_ILV_Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}